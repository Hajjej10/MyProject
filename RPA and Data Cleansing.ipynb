{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15f29a5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded data from page 2\n",
      "Downloaded data from page 3\n",
      "Downloaded data from page 4\n",
      "Downloaded data from page 5\n",
      "Downloaded data from page 6\n",
      "Downloaded data from page 7\n",
      "Downloaded data from page 8\n",
      "Downloaded data from page 9\n",
      "Downloaded data from page 10\n",
      "Downloaded data from page 11\n",
      "Downloaded data from page 12\n",
      "Downloaded data from page 13\n",
      "Downloaded data from page 14\n",
      "Downloaded data from page 15\n",
      "Downloaded and combined data to C:\\Users\\HAJJEJ\\Desktop\\Python test\\Globale.xlsx\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin\n",
    "import pandas as pd\n",
    "\n",
    "# Base URL of the web page\n",
    "base_url = \"https://www.conab.gov.br\"\n",
    "download_dir = r\"C:\\Users\\HAJJEJ\\Desktop\\Python test\"\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "if not os.path.exists(download_dir):\n",
    "    os.makedirs(download_dir)\n",
    "\n",
    "# Create an empty list to store DataFrames\n",
    "dataframes = []\n",
    "\n",
    "# Iterate through pages 2 to 15\n",
    "for page_number in range(2, 16):  # Page numbers from 2 to 15\n",
    "    # URL of the web page for the current page number\n",
    "    url = f\"https://www.conab.gov.br/info-agro/safras/progresso-de-safra?start={page_number * 10}\"\n",
    "\n",
    "    # Send a GET request to the URL\n",
    "    response = requests.get(url)\n",
    "\n",
    "    # Check if the request was successful\n",
    "    if response.status_code == 200:\n",
    "        # Parse the HTML content using BeautifulSoup\n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "        # Find all <a> elements and filter by title attribute\n",
    "        download_links = soup.find_all(\"a\", title=True)\n",
    "\n",
    "        # Iterate through the found links\n",
    "        for download_link in download_links:\n",
    "            title = download_link[\"title\"]\n",
    "            # Check if the title contains \"PlantioZeZColheita\" and has an .xlsx extension\n",
    "            if \"PlantioZeZColheita\" in title and title.endswith(\".xlsx\"):\n",
    "                # Extract the download URL and make it absolute\n",
    "                download_url = urljoin(base_url, download_link.get(\"href\"))\n",
    "\n",
    "                # Download the file\n",
    "                file_content = requests.get(download_url).content\n",
    "\n",
    "                # Read the Excel file into a DataFrame\n",
    "                df = pd.read_excel(pd.ExcelFile(file_content))\n",
    "\n",
    "                # Append the DataFrame to the list\n",
    "                dataframes.append(df)\n",
    "\n",
    "        print(f\"Downloaded data from page {page_number}\")\n",
    "    else:\n",
    "        print(f\"Failed to retrieve data from page {page_number}\")\n",
    "\n",
    "# Concatenate all DataFrames in the list\n",
    "combined_data = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "# Save the combined data to a single Excel file named \"Globale.xlsx\"\n",
    "output_excel_file = os.path.join(download_dir, \"Globale.xlsx\")\n",
    "combined_data.to_excel(output_excel_file, index=False)\n",
    "\n",
    "print(f\"Downloaded and combined data to {output_excel_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee403b73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0          Unnamed: 1 Unnamed: 2 Unnamed: 3 Unnamed: 4\n",
      "0         NaN                 NaN        NaN        NaN        NaN\n",
      "1         NaN                 NaN        NaN        NaN        NaN\n",
      "2         NaN                 NaN        NaN        NaN        NaN\n",
      "3         NaN  Progresso de safra        NaN        NaN        NaN\n",
      "4         NaN                 NaN        NaN        NaN        NaN\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the \"Globale.xlsx\" Excel file\n",
    "excel_file = r\"C:\\Users\\HAJJEJ\\Desktop\\Python test\\Globale.xlsx\"\n",
    "df = pd.read_excel(excel_file)\n",
    "\n",
    "# Display the first few rows of the DataFrame to inspect the data\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa03d74c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0            NaN\n",
      "Unnamed: 1         Estado\n",
      "Unnamed: 2    Semana até:\n",
      "Unnamed: 3            NaN\n",
      "Unnamed: 4            NaN\n",
      "Name: 9, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Find the index where the first occurrence of \"Estado\" is located in column B (index 1)\n",
    "estado_index = df[df.iloc[:, 1] == \"Estado\"].index[0]\n",
    "\n",
    "# Display the row where \"Estado\" is found\n",
    "estado_row = df.iloc[estado_index]\n",
    "print(estado_row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e71509d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0 Unnamed: 1           Unnamed: 2           Unnamed: 3   \n",
      "0         NaN     Estado          Semana até:                  NaN  \\\n",
      "1         NaN        NaN                 2022                 2023   \n",
      "2         NaN        NaN  2022-04-23 00:00:00  2023-04-16 00:00:00   \n",
      "3         NaN   Maranhão                    1                    1   \n",
      "4         NaN      Piauí                    1                    1   \n",
      "\n",
      "            Unnamed: 4  \n",
      "0                  NaN  \n",
      "1                  NaN  \n",
      "2  2023-04-22 00:00:00  \n",
      "3                    1  \n",
      "4                    1  \n",
      "\n",
      "Filtered data saved to C:\\Users\\HAJJEJ\\Desktop\\Python test\\cleansed.xlsx\n"
     ]
    }
   ],
   "source": [
    "# Find the index where the first occurrence of \"Estado\" is located in column B (index 1)\n",
    "estado_index = df[df.iloc[:, 1] == \"Estado\"].index[0]\n",
    "\n",
    "# Create a new DataFrame with rows starting from the \"Estado\" row\n",
    "filtered_df = df.iloc[estado_index:]\n",
    "\n",
    "# Reset the index of the new DataFrame\n",
    "filtered_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Display the new DataFrame to verify the rows have been deleted\n",
    "print(filtered_df.head())\n",
    "\n",
    "# Save the filtered data to a new Excel file (e.g., \"cleansed.xlsx\")\n",
    "output_excel_file = r\"C:\\Users\\HAJJEJ\\Desktop\\Python test\\cleansed.xlsx\"\n",
    "filtered_df.to_excel(output_excel_file, index=False)\n",
    "\n",
    "print(f\"\\nFiltered data saved to {output_excel_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13f6fe79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Unnamed: 1           Unnamed: 3\n",
      "0     Estado                  NaN\n",
      "1        NaN                 2023\n",
      "2        NaN  2023-04-16 00:00:00\n",
      "3   Maranhão                    1\n",
      "4      Piauí                    1\n",
      "\n",
      "Filtered data saved to C:\\Users\\HAJJEJ\\Desktop\\Python test\\final_cleansed.xlsx\n"
     ]
    }
   ],
   "source": [
    "# Select columns with indices 1 and 3\n",
    "filtered_df = filtered_df.iloc[:, [1, 3]]\n",
    "\n",
    "# Display the new DataFrame to verify the selected columns\n",
    "print(filtered_df.head())\n",
    "\n",
    "# Save the filtered data to a new Excel file with only columns 1 and 3\n",
    "output_excel_file = r\"C:\\Users\\HAJJEJ\\Desktop\\Python test\\final_cleansed.xlsx\"\n",
    "filtered_df.to_excel(output_excel_file, index=False)\n",
    "\n",
    "print(f\"\\nFiltered data saved to {output_excel_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef915bdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Location                Value\n",
      "0    Estado                  NaN\n",
      "1       NaN                 2023\n",
      "2       NaN  2023-04-16 00:00:00\n",
      "3  Maranhão                    1\n",
      "4     Piauí                    1\n"
     ]
    },
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'C:\\\\Users\\\\HAJJEJ\\\\Desktop\\\\Python test\\\\final_cleansed.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_8352/1695878308.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# Save the final cleaned data to a new Excel file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0moutput_excel_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mr\"C:\\Users\\HAJJEJ\\Desktop\\Python test\\final_cleansed.xlsx\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mfiltered_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_excel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_excel_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"\\nFiltered data with renamed columns saved to {output_excel_file}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mto_excel\u001b[1;34m(self, excel_writer, sheet_name, na_rep, float_format, columns, header, index, index_label, startrow, startcol, engine, merge_cells, inf_rep, freeze_panes, storage_options)\u001b[0m\n\u001b[0;32m   2250\u001b[0m             \u001b[0minf_rep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minf_rep\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2251\u001b[0m         )\n\u001b[1;32m-> 2252\u001b[1;33m         formatter.write(\n\u001b[0m\u001b[0;32m   2253\u001b[0m             \u001b[0mexcel_writer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2254\u001b[0m             \u001b[0msheet_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msheet_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\formats\\excel.py\u001b[0m in \u001b[0;36mwrite\u001b[1;34m(self, writer, sheet_name, startrow, startcol, freeze_panes, engine, storage_options)\u001b[0m\n\u001b[0;32m    932\u001b[0m             \u001b[1;31m# error: Cannot instantiate abstract class 'ExcelWriter' with abstract\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    933\u001b[0m             \u001b[1;31m# attributes 'engine', 'save', 'supported_extensions' and 'write_cells'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 934\u001b[1;33m             writer = ExcelWriter(  # type: ignore[abstract]\n\u001b[0m\u001b[0;32m    935\u001b[0m                 \u001b[0mwriter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    936\u001b[0m             )\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\excel\\_xlsxwriter.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, path, engine, date_format, datetime_format, mode, storage_options, if_sheet_exists, engine_kwargs, **kwargs)\u001b[0m\n\u001b[0;32m    197\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Append mode is not supported with xlsxwriter!\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m         super().__init__(\n\u001b[0m\u001b[0;32m    200\u001b[0m             \u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m             \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\excel\\_base.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, path, engine, date_format, datetime_format, mode, storage_options, if_sheet_exists, engine_kwargs)\u001b[0m\n\u001b[0;32m   1217\u001b[0m         )\n\u001b[0;32m   1218\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mExcelWriter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1219\u001b[1;33m             self._handles = get_handle(\n\u001b[0m\u001b[0;32m   1220\u001b[0m                 \u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_text\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1221\u001b[0m             )\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    866\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    867\u001b[0m             \u001b[1;31m# Binary mode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 868\u001b[1;33m             \u001b[0mhandle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    869\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    870\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'C:\\\\Users\\\\HAJJEJ\\\\Desktop\\\\Python test\\\\final_cleansed.xlsx'"
     ]
    }
   ],
   "source": [
    "# Rename the first column (column with index 0) to \"Location\" and the second column (column with index 1) to \"Value\"\n",
    "filtered_df.columns = [\"Location\", \"Value\"]\n",
    "\n",
    "# Display the new DataFrame with renamed columns\n",
    "print(filtered_df.head())\n",
    "\n",
    "# Save the final cleaned data to a new Excel file\n",
    "output_excel_file = r\"C:\\Users\\HAJJEJ\\Desktop\\Python test\\final_cleansed.xlsx\"\n",
    "filtered_df.to_excel(output_excel_file, index=False)\n",
    "\n",
    "print(f\"\\nFiltered data with renamed columns saved to {output_excel_file}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b85e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign the constant value \"2022/23\" to the existing \"Crop\" column\n",
    "filtered_df[\"Crop\"] = \"2022/23\"\n",
    "\n",
    "# Display the new DataFrame with the updated \"Crop\" column\n",
    "print(filtered_df.head())\n",
    "\n",
    "# Save the final cleaned data to a new Excel file\n",
    "output_excel_file = r\"C:\\Users\\HAJJEJ\\Desktop\\Python test\\final_cleansed.xlsx\"\n",
    "filtered_df.to_excel(output_excel_file, index=False)\n",
    "\n",
    "print(f\"\\nFiltered data with the updated 'Crop' column saved to {output_excel_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec2a8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column \"Length\" with the length of the \"Value\" column\n",
    "filtered_df[\"Length\"] = filtered_df[\"Value\"].apply(lambda x: len(str(x)))\n",
    "\n",
    "# Display the new DataFrame with the \"Length\" column\n",
    "print(filtered_df.head())\n",
    "\n",
    "# Save the final cleaned data to a new Excel file\n",
    "output_excel_file = r\"C:\\Users\\HAJJEJ\\Desktop\\Python test\\final_cleansed.xlsx\"\n",
    "filtered_df.to_excel(output_excel_file, index=False)\n",
    "\n",
    "print(f\"\\nFiltered data with the 'Length' column saved to {output_excel_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1b3bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert datetime.datetime objects in the \"Value\" column to strings\n",
    "filtered_df[\"Value\"] = filtered_df[\"Value\"].apply(lambda x: str(x))\n",
    "\n",
    "# Create a new column \"Date\" based on the \"Length\" column\n",
    "filtered_df[\"Date\"] = filtered_df.apply(lambda row: row[\"Value\"][:10] if row[\"Length\"] == 19 else None, axis=1)\n",
    "\n",
    "# Display the new DataFrame with the \"Date\" column\n",
    "print(filtered_df.head())\n",
    "\n",
    "# Save the final cleaned data to a new Excel file\n",
    "output_excel_file = r\"C:\\Users\\HAJJEJ\\Desktop\\Python test\\final_cleansed.xlsx\"\n",
    "filtered_df.to_excel(output_excel_file, index=False)\n",
    "\n",
    "print(f\"\\nFiltered data with the 'Date' column saved to {output_excel_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e92b6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8ff851",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill down the \"Date\" column with preceding non-null values\n",
    "filtered_df[\"Date\"].fillna(method=\"ffill\", inplace=True)\n",
    "\n",
    "# Display the new DataFrame with the filled \"Date\" column\n",
    "print(filtered_df.head())\n",
    "\n",
    "# Save the final cleaned data to a new Excel file\n",
    "output_excel_file = r\"C:\\Users\\HAJJEJ\\Desktop\\Python test\\final_cleansed.xlsx\"\n",
    "filtered_df.to_excel(output_excel_file, index=False)\n",
    "\n",
    "print(f\"\\nFiltered data with the 'Date' column filled and saved to {output_excel_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77327f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with NaN values in the \"Location\" column\n",
    "filtered_df = filtered_df.dropna(subset=[\"Location\"])\n",
    "\n",
    "# Display the new DataFrame after dropping NaN values in the \"Location\" column\n",
    "print(filtered_df.head())\n",
    "\n",
    "# Save the final cleaned data to a new Excel file\n",
    "output_excel_file = r\"C:\\Users\\HAJJEJ\\Desktop\\Python test\\final_cleansed.xlsx\"\n",
    "filtered_df.to_excel(output_excel_file, index=False)\n",
    "\n",
    "print(f\"\\nFiltered data with NaN values in 'Location' column removed and saved to {output_excel_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29a166e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with NaN values in the \"Value\" column\n",
    "filtered_df = filtered_df.dropna(subset=[\"Value\"])\n",
    "\n",
    "# Display the new DataFrame after dropping NaN values in the \"Value\" column\n",
    "print(filtered_df.head())\n",
    "\n",
    "# Save the final cleaned data to a new Excel file\n",
    "output_excel_file = r\"C:\\Users\\HAJJEJ\\Desktop\\Python test\\final_cleansed.xlsx\"\n",
    "filtered_df.to_excel(output_excel_file, index=False)\n",
    "\n",
    "print(f\"\\nFiltered data with NaN values in 'Value' column removed and saved to {output_excel_file}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e220457",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with None values in the \"Date\" column\n",
    "filtered_df = filtered_df.dropna(subset=[\"Date\"])\n",
    "\n",
    "# Display the new DataFrame after dropping None values in the \"Date\" column\n",
    "print(filtered_df.head())\n",
    "\n",
    "# Save the final cleaned data to a new Excel file\n",
    "output_excel_file = r\"C:\\Users\\HAJJEJ\\Desktop\\Python test\\final_cleansed.xlsx\"\n",
    "filtered_df.to_excel(output_excel_file, index=False)\n",
    "\n",
    "print(f\"\\nFiltered data with None values in 'Date' column removed and saved to {output_excel_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94dd4b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the \"Length\" column\n",
    "filtered_df.drop(columns=[\"Length\"], inplace=True)\n",
    "\n",
    "# Reorder the DataFrame columns\n",
    "filtered_df = filtered_df[[\"Date\", \"Location\", \"Crop\", \"Value\"]]\n",
    "\n",
    "# Display the updated DataFrame\n",
    "print(filtered_df.head())\n",
    "\n",
    "# Save the final cleaned data to a new Excel file\n",
    "output_excel_file = r\"C:\\Users\\HAJJEJ\\Desktop\\Python test\\final_cleansed.xlsx\"\n",
    "filtered_df.to_excel(output_excel_file, index=False)\n",
    "\n",
    "print(f\"\\nFiltered data with 'Length' column removed and columns reordered saved to {output_excel_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17c6541",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf6e0ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01caf6f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
